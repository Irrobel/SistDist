{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1858ff96-97b6-455b-a90e-7e3e46aab121",
   "metadata": {},
   "source": [
    "### Prueba 7 (RDD) Candidata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d18c2464-0176-4e8f-9121-414c4ccbf369",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/12/10 20:04:47 WARN Utils: Your hostname, gael-guzman-B550MH-3-0 resolves to a loopback address: 127.0.1.1; using 192.168.1.3 instead (on interface enp3s0)\n",
      "25/12/10 20:04:47 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/12/10 20:04:48 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/12/10 20:04:48 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/12/10 20:05:04 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n",
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import split, lower, explode, regexp_replace, size\n",
    "import re\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "spark = SparkSession.builder.appName(\"RecomendacionLibros\").master(\"local[*]\").getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "# 1. Cargar documentos\n",
    "rdd = sc.wholeTextFiles(\"Libros_clean/*.txt\")\n",
    "rdd = rdd.map(lambda x: (re.findall(r\"[^/]+$\", x[0])[0], x[1]))\n",
    "\n",
    "# 2. Limpiar texto y pasar a minúsculas\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^a-zA-Z0-9 \\n]', '', text)\n",
    "    return text.lower()\n",
    "\n",
    "rdd_clean = rdd.map(lambda x: (x[0], clean_text(x[1])))\n",
    "\n",
    "# 3. Quitar stopwords\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "stopwords = StopWordsRemover.loadDefaultStopWords(\"english\")\n",
    "\n",
    "rdd_filtrado = rdd_clean.map(lambda x: (x[0], \" \".join([w for w in x[1].split() if w not in stopwords])))\n",
    "\n",
    "# 4. TF crudo\n",
    "rdd_cont = rdd_filtrado.flatMap(lambda x: [((x[0], w), 1) for w in x[1].split()]).reduceByKey(lambda a, b: a + b)\n",
    "\n",
    "# 5. TF normalizado\n",
    "rdd_total = rdd_cont.map(lambda x: (x[0][0], x[1])).reduceByKey(lambda a, b: a + b)\n",
    "\n",
    "rdd_normalizado = rdd_cont.map(lambda x: (x[0][0], (x[0][1], x[1]))).join(rdd_total)\\\n",
    "                           .map(lambda x: ((x[0], x[1][0][0]), x[1][0][1] / x[1][1]))\n",
    "\n",
    "# 6. DF (document frequency)\n",
    "rdd_doc_unico = rdd_filtrado.flatMap(lambda x: [(w, x[0]) for w in set(x[1].split())])\n",
    "rdd_df = rdd_doc_unico.map(lambda x: (x[0], 1)).reduceByKey(lambda a, b: a + b)\n",
    "\n",
    "# 7. TF-IDF distribuido\n",
    "N = rdd_filtrado.count()\n",
    "\n",
    "rdd_df_map = rdd_df.collectAsMap()  # DF pequeño, cabe en driver\n",
    "rdd_tfidf = rdd_normalizado.map(lambda x: ((x[0][0], x[0][1]), x[1] * math.log(N / rdd_df_map[x[0][1]])))\n",
    "\n",
    "# 8. Crear vectores por documento (RDD distribuido)\n",
    "rdd_vectores = rdd_tfidf.map(lambda x: (x[0][0], (x[0][1], x[1]))).groupByKey()\\\n",
    "                         .mapValues(lambda vals: dict(vals))\n",
    "\n",
    "# 9. Función de similitud coseno\n",
    "def coseno(v1, v2):\n",
    "    palabras = set(v1.keys()).union(v2.keys())\n",
    "    dot = sum(v1.get(p, 0) * v2.get(p, 0) for p in palabras)\n",
    "    norm1 = math.sqrt(sum(v1.get(p, 0)**2 for p in palabras))\n",
    "    norm2 = math.sqrt(sum(v2.get(p, 0)**2 for p in palabras))\n",
    "    if norm1 == 0 or norm2 == 0:\n",
    "        return 0.0\n",
    "    return dot / (norm1 * norm2)\n",
    "\n",
    "# 10. Similitud distribuida\n",
    "rdd_pairs = rdd_vectores.cartesian(rdd_vectores)\\\n",
    "                        .filter(lambda x: x[0][0] < x[1][0])  # Evita pares duplicados y self-similarity\n",
    "\n",
    "rdd_simil = rdd_pairs.map(lambda x: ((x[0][0], x[1][0]), coseno(x[0][1], x[1][1])))\n",
    "top_simil = rdd_simil.takeOrdered(10, key=lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6679a98c-80c7-4137-842b-a923145f72f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Lista de documentos ordenada\n",
    "docs = sorted(rdd_vectores.keys().collect())\n",
    "\n",
    "# Construir diccionario de filas\n",
    "rdd_rows = rdd_vectores.cartesian(rdd_vectores)\\\n",
    "                       .map(lambda x: ((x[0][0], x[1][0]), coseno(x[0][1], x[1][1])))\\\n",
    "                       .map(lambda x: (x[0][0], (x[0][1], x[1])))\\\n",
    "                       .groupByKey()\\\n",
    "                       .mapValues(dict)\n",
    "rows = rdd_rows.collect()\n",
    "\n",
    "# Crear DataFrame asegurando el mismo orden para filas y columnas\n",
    "data = {}\n",
    "for doc, sims in rows:\n",
    "    data[doc] = [sims.get(d, 0.0) for d in docs]\n",
    "\n",
    "df = pd.DataFrame(data, index=docs, columns=docs)\n",
    "\n",
    "#print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2d4b2e8-6f7b-463a-a799-4a354a119176",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "\n",
    "# Convertimos la matriz de similitud RDD a DataFrame Pandas\n",
    "docs = rdd_vectores.keys().collect()\n",
    "sim_matrix = pd.DataFrame(0, index=docs, columns=docs, dtype=float)\n",
    "\n",
    "for ((doc1, doc2), sim) in rdd_simil.collect():\n",
    "    sim_matrix.loc[doc1, doc2] = sim\n",
    "    sim_matrix.loc[doc2, doc1] = sim\n",
    "\n",
    "# Colocar 1.0 en la diagonal\n",
    "for d in docs:\n",
    "    sim_matrix.loc[d, d] = 1.0\n",
    "\n",
    "# Función 1️⃣: libros más parecidos\n",
    "def libros_parecidos():\n",
    "    doc = input(\"Ingrese el nombre del documento (ej: Doc1.txt): \")\n",
    "    n = int(input(\"Ingrese la cantidad de libros parecidos que desea: \"))\n",
    "    \n",
    "    if doc not in sim_matrix.index:\n",
    "        print(\"Documento no encontrado.\")\n",
    "        return\n",
    "    \n",
    "    similitudes_doc = sim_matrix.loc[doc].drop(doc)  # Quitamos el propio doc\n",
    "    top_docs = similitudes_doc.sort_values(ascending=False).head(n)\n",
    "    print(f\"\\nLos {n} libros más parecidos a '{doc}' son:\")\n",
    "    print(top_docs)\n",
    "\n",
    "vec_dict = rdd_vectores.collectAsMap()\n",
    "# Función 2️⃣: cantidad de palabras que describen un documento\n",
    "def cantidad_palabras():\n",
    "    doc = input(\"Ingrese el nombre del documento (ej: Doc1.txt): \")\n",
    "    n = int(input(\"Ingrese la cantidad de palabras que desea ver que describen el documento: \"))\n",
    "    \n",
    "    if doc not in vec_dict:\n",
    "        print(\"Documento no encontrado.\")\n",
    "        return\n",
    "    \n",
    "    vec = vec_dict[doc]  # Diccionario de palabras y TF-IDF\n",
    "    \n",
    "    # Ordenar las palabras por TF-IDF descendente y tomar las top n\n",
    "    top_words = sorted(vec.items(), key=lambda x: x[1], reverse=True)[:n]\n",
    "    \n",
    "    print(f\"\\nLas {n} palabras que describen mejor el documento '{doc}' son:\")\n",
    "    for palabra, tfidf in top_words:\n",
    "        print(f\"{palabra} : {tfidf:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8940a95e-cf5d-4e13-8976-ddbadac574f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Ingrese el nombre del documento (ej: Doc1.txt):  A_Tale_of_Two_Cities_by_Charles_Dickens.txt\n",
      "Ingrese la cantidad de palabras que desea ver que describen el documento:  20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Las 20 palabras que describen mejor el documento 'A_Tale_of_Two_Cities_by_Charles_Dickens.txt' son:\n",
      "lorry : 0.0207\n",
      "defarge : 0.0203\n",
      "manette : 0.0112\n",
      "pross : 0.0108\n",
      "darnay : 0.0101\n",
      "carton : 0.0090\n",
      "lucie : 0.0090\n",
      "cruncher : 0.0078\n",
      "stryver : 0.0075\n",
      "tellsons : 0.0060\n",
      "jerry : 0.0050\n",
      "monseigneur : 0.0048\n",
      "evrmonde : 0.0033\n",
      "wineshop : 0.0032\n",
      "madame : 0.0032\n",
      "barsad : 0.0032\n",
      "sydney : 0.0030\n",
      "jacques : 0.0023\n",
      "mender : 0.0023\n",
      "lorrys : 0.0022\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de uso:\n",
    "#libros_parecidos()\n",
    "cantidad_palabras()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "760ed6f2-7268-4f2c-92c9-9ee4e7830737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Ingrese el nombre del documento (ej: Doc1.txt):  A_Tale_of_Two_Cities_by_Charles_Dickens.txt\n",
      "Ingrese la cantidad de libros parecidos que desea:  20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Los 20 libros más parecidos a 'A_Tale_of_Two_Cities_by_Charles_Dickens.txt' son:\n",
      "The_Adventures_of_Roderick_Random_by_T._Smollett.txt                                                       0.030836\n",
      "The_Works_of_Edgar_Allan_Poe_—_Volume_2_by_Edgar_Allan_Poe.txt                                             0.025720\n",
      "Jane_Eyre_An_Autobiography_by_Charlotte_Brontë.txt                                                         0.023761\n",
      "The_Interesting_Narrative_of_the_Life_of_Olaudah_Equiano,_Or_Gustavus_Vassa,_The_African_by_Equiano.txt    0.023346\n",
      "Romantic_castles_and_palaces_.txt                                                                          0.022054\n",
      "Les_Misérables_by_Victor_Hugo.txt                                                                          0.021922\n",
      "Ulysses_by_James_Joyce.txt                                                                                 0.021419\n",
      "How_to_Observe_Morals_and_Manners_by_Harriet_Martineau.txt                                                 0.021299\n",
      "The_King_in_Yellow_by_Robert_W._Chambers.txt                                                               0.021276\n",
      "Walden,_and_On_The_Duty_Of_Civil_Disobedience_by_Henry_David_Thoreau.txt                                   0.021214\n",
      "The_Expedition_of_Humphry_Clinker_by_T._Smollett.txt                                                       0.020555\n",
      "Frankenstein;_Or,_The_Modern_Prometheus_by_Mary_Wollstonecraft_Shelley.txt                                 0.018731\n",
      "Treasure_Island_by_Robert_Louis_Stevenson.txt                                                              0.018098\n",
      "Bleak_House_by_Charles_Dickens.txt                                                                         0.017948\n",
      "On_Liberty_by_John_Stuart_Mill.txt                                                                         0.017466\n",
      "The_Adventures_of_Ferdinand_Count_Fathom_—_Complete_by_T._Smollett.txt                                     0.017432\n",
      "Grimms'_Fairy_Tales_by_Jacob_Grimm_and_Wilhelm_Grimm.txt                                                   0.017390\n",
      "Paradise_Lost_by_John_Milton.txt                                                                           0.017336\n",
      "The_Republic_by_Plato.txt                                                                                  0.017318\n",
      "Beyond_Good_and_Evil_by_Friedrich_Wilhelm_Nietzsche.txt                                                    0.016524\n",
      "Name: A_Tale_of_Two_Cities_by_Charles_Dickens.txt, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "libros_parecidos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22dededd-ceb5-4c45-bd54-c24a3503c167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('A_Christmas_Carol_in_Prose;_Being_a_Ghost_Story_of_Christmas_by_Charles_Dickens.txt',\n",
       "   'christmas'),\n",
       "  0.006421951397504196),\n",
       " (('A_Christmas_Carol_in_Prose;_Being_a_Ghost_Story_of_Christmas_by_Charles_Dickens.txt',\n",
       "   'carol'),\n",
       "  0.00029190688170473617),\n",
       " (('A_Christmas_Carol_in_Prose;_Being_a_Ghost_Story_of_Christmas_by_Charles_Dickens.txt',\n",
       "   'story'),\n",
       "  0.00029190688170473617)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_normalizado.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a70b884-1034-4ecf-9cd5-9e05a91c8ecd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
